{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "59a7c749",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting boto3\n",
      "  Downloading boto3-1.35.84-py3-none-any.whl (139 kB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m139.2/139.2 kB\u001b[0m \u001b[31m501.3 kB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0ma \u001b[36m0:00:01\u001b[0m\n",
      "\u001b[?25hCollecting jmespath<2.0.0,>=0.7.1\n",
      "  Downloading jmespath-1.0.1-py3-none-any.whl (20 kB)\n",
      "Collecting s3transfer<0.11.0,>=0.10.0\n",
      "  Downloading s3transfer-0.10.4-py3-none-any.whl (83 kB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m83.2/83.2 kB\u001b[0m \u001b[31m4.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hCollecting botocore<1.36.0,>=1.35.84\n",
      "  Downloading botocore-1.35.84-py3-none-any.whl (13.3 MB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m13.3/13.3 MB\u001b[0m \u001b[31m26.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0ma \u001b[36m0:00:01\u001b[0m\n",
      "\u001b[?25hRequirement already satisfied: python-dateutil<3.0.0,>=2.1 in /Users/chuanxie/.pyenv/versions/3.10.15/lib/python3.10/site-packages (from botocore<1.36.0,>=1.35.84->boto3) (2.9.0.post0)\n",
      "Collecting urllib3!=2.2.0,<3,>=1.25.4\n",
      "  Downloading urllib3-2.2.3-py3-none-any.whl (126 kB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m126.3/126.3 kB\u001b[0m \u001b[31m14.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hRequirement already satisfied: six>=1.5 in /Users/chuanxie/.pyenv/versions/3.10.15/lib/python3.10/site-packages (from python-dateutil<3.0.0,>=2.1->botocore<1.36.0,>=1.35.84->boto3) (1.17.0)\n",
      "Installing collected packages: urllib3, jmespath, botocore, s3transfer, boto3\n",
      "Successfully installed boto3-1.35.84 botocore-1.35.84 jmespath-1.0.1 s3transfer-0.10.4 urllib3-2.2.3\n",
      "\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m A new release of pip is available: \u001b[0m\u001b[31;49m23.0.1\u001b[0m\u001b[39;49m -> \u001b[0m\u001b[32;49m24.3.1\u001b[0m\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m To update, run: \u001b[0m\u001b[32;49mpip install --upgrade pip\u001b[0m\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "%pip install boto3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "d87b3c05-9ad6-4a58-ae21-c699a18107af",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import boto3\n",
    "import json\n",
    "import base64\n",
    "import time\n",
    "import os\n",
    "from botocore.config import Config\n",
    "config = Config(\n",
    "       connect_timeout=1000,\n",
    "    read_timeout=1000,\n",
    ")\n",
    "\n",
    "session = boto3.session.Session(region_name='us-east-1')\n",
    "client = session.client(service_name = 'bedrock-runtime', \n",
    "                                 config=config)\n",
    "\n",
    "\n",
    "PRO_MODEL_ID = \"us.amazon.nova-pro-v1:0\"\n",
    "LITE_MODEL_ID = \"us.amazon.nova-lite-v1:0\"\n",
    "MICRO_MODEL_ID = \"us.amazon.nova-micro-v1:0\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "6fb36c95-0cf1-428e-aeee-225d516d3341",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "from json import JSONDecodeError\n",
    "import re\n",
    "def parse(text: str) -> str:\n",
    "    pattern = r\"<prompt>(.*?)</prompt>\"\n",
    "    match = re.search(pattern, text, re.DOTALL)\n",
    "    if match:\n",
    "        text = match.group(1)\n",
    "        return text.strip()\n",
    "    else:\n",
    "        raise JSONDecodeError"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "d9bbb0e3-0bae-4be1-98a1-8b10a7f06d01",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "with open(\"Amazon_Nova_Reel.pdf\", \"rb\") as file:\n",
    "    doc_bytes = file.read()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c97d83d4-39ef-491f-aa20-8bcdf1403f2b",
   "metadata": {},
   "source": [
    "## Reel\n",
    "- text 2 video"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "17afc48d-4d6f-466c-980b-c831e5b20b1e",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "system_1 = \\\n",
    "\"\"\"\n",
    "You are a Prompt Rewriting Expert for text-to-video models, with extensive knowledge in film and video production. \n",
    "You specialize in helping users improve their text prompts according to specific rules to achieve better model outputs, sometimes modifying the original intent if necessary. \n",
    "\n",
    "##You excel in the following areas:##\n",
    "Comprehensive understanding of the world, physical laws, and various interactive video scenarios\n",
    "Rich imagination to visualize perfect, visually striking video scenes from simple prompts\n",
    "Extensive film industry expertise as a master director, capable of enhancing simple video descriptions with optimal cinematography and visual effects\n",
    "\n",
    "##Your prompt rewriting should follow these guidelines:##\n",
    "Prompting for video generation models differs from prompting for large language models (LLMs). \n",
    "Video generation models do not have the ability to reason or interpret explicit commands. \n",
    "Therefore, it's best to phrase your prompt as if it were an image caption or summary of the video rather than a command or conversation. \n",
    "You may want to include details about the subject, action, environment, lighting, style, and camera motion.\n",
    "Subject: Add detailed characteristics of video subjects\n",
    "Scene: Elaborate background details based on context\n",
    "Emotional atmosphere: Describe the mood and overall ambiance\n",
    "Cinematography: Specify shot types, camera angles, and perspectives (avoid complex camera movements)， Please refer to the guideline in DocumentPDFmessages.\n",
    "Visual effects: Define style (e.g., Pixar, cinematic, hyperrealistic, 3D animation) and describe lighting, color tones, and contrast.\n",
    "\n",
    "\n",
    "##Good Examples##\n",
    "- Prompt: \"Cinematic dolly shot of a juicy cheeseburger with melting cheese, fries, and a condensation-covered cola on a worn diner table. Natural lighting, visible steam and droplets. 4k, photorealistic, shallow depth of field\"\n",
    "- Prompt: \"Arc shot on a salad with dressing, olives and other vegetables; 4k; Cinematic;\"\n",
    "- Prompt: \"First person view of a motorcycle riding through the forest road.\"\n",
    "- Prompt: \"Closeup of a large seashell in the sand. Gentle waves flow around the shell. Camera zoom in.\"\n",
    "- Prompt: \"Clothes hanging on a thread to dry, windy; sunny day; 4k; Cinematic; highest quality;\"\n",
    "- Prompt: \"Slow cam of a man middle age; 4k; Cinematic; in a sunny day; peaceful; highest quality; dolly in;\"\n",
    "- Prompt: \"A mushroom drinking a cup of coffee while sitting on a couch, photorealistic.\"\n",
    "\n",
    "##Ouput instruction##\n",
    "Users may input prompts in Chinese or English, but your final output should be a single English paragraph not exceeding 90 words.\n",
    "Put your reponse in <prompt></prompt>\n",
    "\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "4d0ab939-0a6a-4302-a90a-a2048b5d489f",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "user_prompt = \"In a nighttime forest, three glowing fireflies flutter about.\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "bd63dab1-db4e-4372-b77b-86e40462fe62",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<prompt>A nighttime forest scene with three glowing fireflies fluttering about, captured from a first-person aerial view. The forest is illuminated by the soft, natural light of the fireflies, creating a magical and serene atmosphere. The camera moves in slowly, enhancing the enchanting quality of the scene. Ultra HD, 8K resolution, photorealistic details.</prompt>CPU times: user 55.8 ms, sys: 16.2 ms, total: 72.1 ms\n",
      "Wall time: 3.84 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "system = [\n",
    "    {\n",
    "        \"text\": system_1\n",
    "    }\n",
    "]\n",
    "\n",
    "messages = [\n",
    "    {\n",
    "        \"role\": \"user\",\n",
    "        \"content\": [\n",
    "         {\n",
    "            \"document\": {\n",
    "                \"format\": \"pdf\",\n",
    "                \"name\": \"DocumentPDFmessages\",\n",
    "                \"source\": {\n",
    "                    \"bytes\": doc_bytes\n",
    "                }\n",
    "            }\n",
    "        },\n",
    "         {\"text\": user_prompt},\n",
    "        ],\n",
    "    }\n",
    "]\n",
    "\n",
    "# Configure the inference parameters.\n",
    "inf_params = {\"maxTokens\": 2000, \"topP\": 0.9, \"temperature\": 0.3}\n",
    "\n",
    "\n",
    "model_response = client.converse_stream(\n",
    "    modelId=LITE_MODEL_ID, messages=messages, system=system, inferenceConfig=inf_params\n",
    ")\n",
    "\n",
    "text = \"\"\n",
    "stream = model_response.get(\"stream\")\n",
    "if stream:\n",
    "    for event in stream:\n",
    "        if \"contentBlockDelta\" in event:\n",
    "            text += event[\"contentBlockDelta\"][\"delta\"][\"text\"]\n",
    "            print(event[\"contentBlockDelta\"][\"delta\"][\"text\"], end=\"\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "bc75fabe-49bd-4353-8e29-d3725dc28fa7",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "350\n",
      "A nighttime forest scene with three glowing fireflies fluttering about, captured from a first-person aerial view. The forest is illuminated by the soft, natural light of the fireflies, creating a magical and serene atmosphere. The camera moves in slowly, enhancing the enchanting quality of the scene. Ultra HD, 8K resolution, photorealistic details.\n"
     ]
    }
   ],
   "source": [
    "generated_prompt = parse(text)\n",
    "print(len(generated_prompt))\n",
    "print(generated_prompt)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "bc881297-0d1c-4b5d-9d4a-e05146339c44",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "BUCKET = \"s3://bedrock-video-generation-us-east-1-jlvyiv\"\n",
    "bedrock_runtime = session.client(\"bedrock-runtime\")\n",
    "\n",
    "\n",
    "def generate_video(bucket,text_prompt,input_image_base64=None):\n",
    "    model_input = {\n",
    "        \"taskType\": \"TEXT_VIDEO\",\n",
    "        \"textToVideoParams\": {\n",
    "            \"text\": generated_prompt,\n",
    "        },\n",
    "        \"videoGenerationConfig\": {\n",
    "            \"durationSeconds\": 6,\n",
    "            \"fps\": 24,\n",
    "            \"dimension\": \"1280x720\",\n",
    "            \"seed\": 0,  # Change the seed to get a different result\n",
    "        },\n",
    "    }\n",
    "    if input_image_base64:\n",
    "        model_input['textToVideoParams']['images'] =  [\n",
    "            {\n",
    "                \"format\": \"png\",\n",
    "                \"source\": {\n",
    "                    \"bytes\": input_image_base64\n",
    "                }\n",
    "            }\n",
    "            ]\n",
    "\n",
    "    try:\n",
    "        # Start the asynchronous video generation job.\n",
    "        invocation = bedrock_runtime.start_async_invoke(\n",
    "            modelId=\"amazon.nova-reel-v1:0\",\n",
    "            modelInput=model_input,\n",
    "            outputDataConfig={\n",
    "                \"s3OutputDataConfig\": {\n",
    "                    \"s3Uri\": BUCKET\n",
    "                }\n",
    "            }\n",
    "        )\n",
    "        return invocation\n",
    "\n",
    "    except Exception as e:\n",
    "        # Implement error handling here.\n",
    "        message = e.response[\"Error\"][\"Message\"]\n",
    "        print(f\"Error: {message}\")\n",
    "        return None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "9fe005a0-a3ef-4ddf-a46b-bd6d17b47ab2",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Status: InProgress\n",
      "Status: InProgress\n",
      "Status: InProgress\n",
      "Status: InProgress\n",
      "Status: InProgress\n",
      "Status: InProgress\n",
      "Status: InProgress\n",
      "Status: InProgress\n",
      "Status: InProgress\n",
      "Status: InProgress\n",
      "Status: InProgress\n",
      "Status: InProgress\n",
      "Status: InProgress\n",
      "Status: InProgress\n",
      "Status: InProgress\n",
      "Status: InProgress\n",
      "Status: InProgress\n",
      "Status: InProgress\n",
      "Status: InProgress\n",
      "Status: InProgress\n",
      "Status: InProgress\n",
      "Status: InProgress\n",
      "Status: InProgress\n",
      "Status: InProgress\n",
      "Status: InProgress\n",
      "Status: InProgress\n",
      "Status: Completed\n"
     ]
    }
   ],
   "source": [
    "invocation = generate_video(bucket= BUCKET, text_prompt = generated_prompt)\n",
    "\n",
    "while 1:\n",
    "    response = bedrock_runtime.get_async_invoke(\n",
    "        invocationArn=invocation['invocationArn']\n",
    "    )\n",
    "    status = response[\"status\"]\n",
    "    print(f\"Status: {status}\")\n",
    "    time.sleep(10)\n",
    "    if not status == 'InProgress':\n",
    "        break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "4553d874-0986-4743-9f02-3a279fa4b7cc",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import random\n",
    "import string\n",
    "def random_string_name(length=12):\n",
    "        return ''.join(random.choices(string.ascii_lowercase + string.digits, k=length))\n",
    "\n",
    "def download_video_from_s3(s3_uri, local_path):\n",
    "    \"\"\"\n",
    "    Download a video file from S3 to local storage\n",
    "    \n",
    "    Parameters:\n",
    "    s3_uri (str): S3 URI in format 's3://bucket-name/path/to/video.mp4'\n",
    "    local_path (str): Local path where the video will be saved\n",
    "    \"\"\"\n",
    "    try:\n",
    "        # Initialize S3 client\n",
    "        s3_client = boto3.client('s3')\n",
    "        \n",
    "        # Parse S3 URI to get bucket and key\n",
    "        if not s3_uri.startswith('s3://'):\n",
    "            raise ValueError(\"Invalid S3 URI format. Must start with 's3://'\")\n",
    "        \n",
    "        # Remove 's3://' and split into bucket and key\n",
    "        path_parts = s3_uri[5:].split('/', 1)\n",
    "        if len(path_parts) != 2:\n",
    "            raise ValueError(\"Invalid S3 URI format\")\n",
    "        \n",
    "        bucket_name = path_parts[0]\n",
    "        s3_key = path_parts[1]\n",
    "        \n",
    "        # Create directory if it doesn't exist\n",
    "        os.makedirs(local_path, exist_ok=True)\n",
    "        fname = s3_key.split('/')[0]+'.mp4'\n",
    "        # Download the file\n",
    "        print(f\"Downloading {s3_key} to {local_path}/{fname}\")\n",
    "        s3_client.download_file(bucket_name, s3_key, local_path+'/'+fname)\n",
    "        print(\"Download completed successfully!\")\n",
    "        \n",
    "        return f\"{local_path}/{fname}\"\n",
    "        \n",
    "    except Exception as e:\n",
    "        print(f\"Error downloading file: {str(e)}\")\n",
    "        return False\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "36961312-ed86-46c8-b241-3e1aae25f932",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Downloading nz4ftrmf67ht/output.mp4 to ./generated_videos/nz4ftrmf67ht.mp4\n",
      "Download completed successfully!\n"
     ]
    }
   ],
   "source": [
    "output_uri = response['outputDataConfig']['s3OutputDataConfig']['s3Uri']+'/output.mp4'\n",
    "file_name = download_video_from_s3(output_uri,'./generated_videos')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "015e563f-6147-4086-883b-4b8c5699d0a4",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<video src=\"./generated_videos/nz4ftrmf67ht.mp4\" controls  width=\"1280\"  height=\"720\">\n",
       "      Your browser does not support the <code>video</code> element.\n",
       "    </video>"
      ],
      "text/plain": [
       "<IPython.core.display.Video object>"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from IPython.display import Video, HTML\n",
    "Video(file_name,width=1280, height=720)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2975671c-64b0-432d-8bf3-00e0986ae9e3",
   "metadata": {},
   "source": [
    "## Image to Video"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "128716d0-05a6-4ba5-819f-bb584815d84e",
   "metadata": {},
   "source": [
    "### 处理图片"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "id": "20bcd3cb-a7c2-4397-9377-89accbf0ef18",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "from PIL import Image\n",
    "\n",
    "def resize_image(image_path, output_path, target_width=1280, target_height=720):\n",
    "    try:\n",
    "        # 打开图片\n",
    "        img = Image.open(image_path)\n",
    "        \n",
    "        # 获取原始图片尺寸\n",
    "        original_width, original_height = img.size\n",
    "        \n",
    "        # 如果图片小于目标尺寸，直接返回原图\n",
    "        if original_width <= target_width and original_height <= target_height:\n",
    "            # img.save(output_path, quality=95)\n",
    "            return\n",
    "        \n",
    "        # 计算目标宽高比\n",
    "        target_ratio = target_width / target_height\n",
    "        \n",
    "        # 计算原始图片宽高比\n",
    "        original_ratio = original_width / original_height\n",
    "        \n",
    "        # 裁剪图片以匹配目标比例\n",
    "        if original_ratio > target_ratio:\n",
    "            # 图片太宽，需要裁剪宽度\n",
    "            new_width = int(original_height * target_ratio)\n",
    "            left = (original_width - new_width) // 2\n",
    "            img = img.crop((left, 0, left + new_width, original_height))\n",
    "        elif original_ratio < target_ratio:\n",
    "            # 图片太高，需要裁剪高度\n",
    "            new_height = int(original_width / target_ratio)\n",
    "            top = (original_height - new_height) // 2\n",
    "            img = img.crop((0, top, original_width, top + new_height))\n",
    "        \n",
    "        # 调整图片大小到目标尺寸\n",
    "        img = img.resize((target_width, target_height), Image.Resampling.LANCZOS)\n",
    "        \n",
    "        # 保存处理后的图片\n",
    "        img.save(output_path, quality=95)\n",
    "        print(f\"图片处理完成: {output_path}\")\n",
    "        \n",
    "    except Exception as e:\n",
    "        print(f\"处理图片时出错: {str(e)}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "id": "ddadbfb8-444c-44ed-b613-c69e5ef9d4c3",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "图片处理完成: output_image/19.png\n",
      "图片处理完成: output_image/7.png\n",
      "图片处理完成: output_image/15.png\n",
      "图片处理完成: output_image/8.png\n",
      "图片处理完成: output_image/9.jpeg\n",
      "图片处理完成: output_image/3.jpg\n",
      "图片处理完成: output_image/18.png\n",
      "图片处理完成: output_image/12.png\n",
      "图片处理完成: output_image/10.png\n",
      "图片处理完成: output_image/17.png\n"
     ]
    }
   ],
   "source": [
    "input_folder = \"2\"\n",
    "output_folder = \"output_image\"\n",
    "\n",
    "# 确保输出文件夹存在\n",
    "os.makedirs(output_folder, exist_ok=True)\n",
    "\n",
    "for filename in os.listdir(input_folder):\n",
    "    if filename.lower().endswith(('.png', '.jpg', '.jpeg')):\n",
    "        input_path = os.path.join(input_folder, filename)\n",
    "        output_path = os.path.join(output_folder, filename)\n",
    "        resize_image(input_path, output_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "bfaa1c08-f7a9-4ad4-b235-a2431ba43be1",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "system_2 = \\\n",
    "\"\"\"\n",
    "You are a Prompt rewriting expert for image-to-video models, with expertise in film industry knowledge and skilled at helping users output final text prompts based on input initial frame images and potentially accompanying text prompts. \n",
    "The main goal is to help other models produce better video outputs based on these prompts and initial frame images. Users may input only images or both an image and text prompt, where the text could be in Chinese or English.\n",
    "Your final output should be a single paragraph of English prompt not exceeding 90 words.\n",
    "\n",
    "##You are proficient in the knowledge mentioned in:##\n",
    "-You have a comprehensive understanding of the world, knowing various physical laws and can envision video content showing interactions between all things.\n",
    "-You are imaginative and can envision the most perfect, visually impactful video scenes based on user-input images and prompts.\n",
    "-You possess extensive film industry knowledge as a master director, capable of supplementing the best cinematographic language and visual effects based on user-input images and simple descriptions.\n",
    "\n",
    "\n",
    "##Please follow these guidelines for rewriting prompts:##\n",
    "-Subject: Based on user-uploaded image content, describe the video subject's characteristics in detail, emphasizing details while adjusting according to user's text prompt.\n",
    "-Scene: Detailed description of video background, including location, environment, setting, season, time, etc., emphasizing details.\n",
    "-Emotion and Atmosphere: Description of emotions and overall atmosphere conveyed in the video, referencing the image and user's prompt.\n",
    "Cinematography: Specify shot types, camera angles, and perspectives, Please refer to the guideline in DocumentPDFmessages.\n",
    "-Visual Effects: Description of the visual style from user-uploaded images, such as Pixar animation, film style, realistic style, 3D animation, including descriptions of color schemes, lighting types, and contrast.\n",
    "\n",
    "##Good Examples##\n",
    "- Prompt: \"Cinematic dolly shot of a juicy cheeseburger with melting cheese, fries, and a condensation-covered cola on a worn diner table. Natural lighting, visible steam and droplets. 4k, photorealistic, shallow depth of field\"\n",
    "- Prompt: \"Arc shot on a salad with dressing, olives and other vegetables; 4k; Cinematic;\"\n",
    "- Prompt: \"First person view of a motorcycle riding through the forest road.\"\n",
    "- Prompt: \"Closeup of a large seashell in the sand. Gentle waves flow around the shell. Camera zoom in.\"\n",
    "- Prompt: \"Clothes hanging on a thread to dry, windy; sunny day; 4k; Cinematic; highest quality;\"\n",
    "- Prompt: \"Slow cam of a man middle age; 4k; Cinematic; in a sunny day; peaceful; highest quality; dolly in;\"\n",
    "- Prompt: \"A mushroom drinking a cup of coffee while sitting on a couch, photorealistic.\"\n",
    "\n",
    "##Ouput instruction##\n",
    "Users may input prompts in Chinese or English, but your final output should be a single English paragraph not exceeding 90 words.\n",
    "Put your reponse in <prompt></prompt>\n",
    "\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "id": "3cd41db0-c2fa-4514-ba65-cdd22abf6b56",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "user_prompt = \"冬季的树林中，红色的火车缓缓向前行驶.\"\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "id": "c218829c-2c7d-4b09-afae-46dc8703ada5",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting python-magic\n",
      "  Downloading python_magic-0.4.27-py2.py3-none-any.whl.metadata (5.8 kB)\n",
      "Downloading python_magic-0.4.27-py2.py3-none-any.whl (13 kB)\n",
      "Installing collected packages: python-magic\n",
      "Successfully installed python-magic-0.4.27\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "%pip install python-magic"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "id": "a3db6bf4-4302-45aa-a8a9-804bc9bc4fbb",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import magic\n",
    "def img_mime(image_path):\n",
    "    try:\n",
    "        mime = magic.Magic(mime=True)\n",
    "        return mime.from_file(image_path)\n",
    "    \n",
    "    except Exception as e:\n",
    "        print(f\"python-magic detection error: {str(e)}\")\n",
    "        return None\n",
    "            \n",
    "with open(image_file, \"rb\") as f:\n",
    "    image = f.read()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "id": "c2746835-a8d4-489c-a222-a2e70e9a57ac",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'image/jpeg'"
      ]
     },
     "execution_count": 65,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "image_file = \"output_image/3.jpg\"\n",
    "mime_type = img_mime(image_file)\n",
    "mime_type"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "id": "0843227d-ee5a-4db5-b27b-203d842d49a4",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<prompt>A vintage red train slowly moves through a snowy forest in winter, with a monochromatic filter enhancing the serene atmosphere. The camera captures a first-person aerial view, dolly in shot, zooming in on the train as it glides along the tracks, surrounded by tall trees and a cloudy sky. Ultra HD, 8K resolution, photorealistic details.</prompt>CPU times: user 24.1 ms, sys: 8.08 ms, total: 32.2 ms\n",
      "Wall time: 2.59 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "system = [\n",
    "    {\n",
    "        \"text\": system_2\n",
    "    }\n",
    "]\n",
    "\n",
    "messages = [\n",
    "    {\n",
    "        \"role\": \"user\",\n",
    "        \"content\": [\n",
    "         {\n",
    "            \"document\": {\n",
    "                \"format\": \"pdf\",\n",
    "                \"name\": \"DocumentPDFmessages\",\n",
    "                \"source\": {\n",
    "                    \"bytes\": doc_bytes\n",
    "                }\n",
    "            }\n",
    "        },\n",
    "        {\"image\": {\"format\": mime_type.split('/')[1], \"source\": {\"bytes\": image}}},\n",
    "         {\"text\": user_prompt},\n",
    "        ],\n",
    "    }\n",
    "]\n",
    "\n",
    "# Configure the inference parameters.\n",
    "inf_params = {\"maxTokens\": 2000, \"topP\": 0.9, \"temperature\": 0.3}\n",
    "\n",
    "\n",
    "model_response = client.converse_stream(\n",
    "    modelId=LITE_MODEL_ID, messages=messages, system=system, inferenceConfig=inf_params\n",
    ")\n",
    "\n",
    "text = \"\"\n",
    "stream = model_response.get(\"stream\")\n",
    "if stream:\n",
    "    for event in stream:\n",
    "        if \"contentBlockDelta\" in event:\n",
    "            text += event[\"contentBlockDelta\"][\"delta\"][\"text\"]\n",
    "            print(event[\"contentBlockDelta\"][\"delta\"][\"text\"], end=\"\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "id": "20253f5c-5745-4694-b2d8-1120e94425a2",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "337\n",
      "A vintage red train slowly moves through a snowy forest in winter, with a monochromatic filter enhancing the serene atmosphere. The camera captures a first-person aerial view, dolly in shot, zooming in on the train as it glides along the tracks, surrounded by tall trees and a cloudy sky. Ultra HD, 8K resolution, photorealistic details.\n"
     ]
    }
   ],
   "source": [
    "generated_prompt = parse(text)\n",
    "print(len(generated_prompt))\n",
    "print(generated_prompt)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "id": "5182d4d7-0fb4-4a7d-b52f-01141ac6611d",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Status: InProgress\n",
      "Status: InProgress\n",
      "Status: InProgress\n",
      "Status: InProgress\n",
      "Status: InProgress\n",
      "Status: InProgress\n",
      "Status: InProgress\n",
      "Status: InProgress\n",
      "Status: InProgress\n",
      "Status: InProgress\n",
      "Status: InProgress\n",
      "Status: InProgress\n",
      "Status: InProgress\n",
      "Status: InProgress\n",
      "Status: InProgress\n",
      "Status: InProgress\n",
      "Status: InProgress\n",
      "Status: InProgress\n",
      "Status: InProgress\n",
      "Status: InProgress\n",
      "Status: InProgress\n",
      "Status: InProgress\n",
      "Status: Completed\n"
     ]
    }
   ],
   "source": [
    "with open(image_file, \"rb\") as f:\n",
    "    image_bytes = f.read()\n",
    "    image_base64 = base64.b64encode(image_bytes).decode(\"utf-8\")\n",
    "    \n",
    "invocation = generate_video(bucket= BUCKET, text_prompt = generated_prompt,input_image_base64=image_base64)\n",
    "\n",
    "while 1:\n",
    "    response = bedrock_runtime.get_async_invoke(\n",
    "        invocationArn=invocation['invocationArn']\n",
    "    )\n",
    "    status = response[\"status\"]\n",
    "    print(f\"Status: {status}\")\n",
    "    time.sleep(10)\n",
    "    if not status == 'InProgress':\n",
    "        break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "id": "c674700c-053b-4c89-b792-6bc478f3d091",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Downloading s3://bedrock-video-generation-us-east-1-jlvyiv/ybztjuqblhol/output.mp4 to ./generated_videos/i12vcd09tbor.mp4\n",
      "Download completed successfully!\n"
     ]
    }
   ],
   "source": [
    "output_uri = response['outputDataConfig']['s3OutputDataConfig']['s3Uri']+'/output.mp4'\n",
    "file_name = download_video_from_s3(output_uri,'./generated_videos')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "id": "ffcb6df6-3d1e-4a2d-b9c9-7b54979fbd64",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<video src=\"./generated_videos/i12vcd09tbor.mp4\" controls  width=\"1280\"  height=\"720\">\n",
       "      Your browser does not support the <code>video</code> element.\n",
       "    </video>"
      ],
      "text/plain": [
       "<IPython.core.display.Video object>"
      ]
     },
     "execution_count": 73,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Video(file_name,width=1280, height=720)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e8ed9ce9-986a-40de-9454-9645d756c6d2",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "3.10.15",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.15"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
